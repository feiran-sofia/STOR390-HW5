---
title: "HW 5"
author: "Sofia Zhang"
date: "11/08/2024"
output:
  pdf_document: default
  html_document:
    number_sections: yes
---

This homework is meant to give you practice in creating and defending a position with both statistical and philosophical evidence.  We have now extensively talked about the COMPAS ^[https://www.propublica.org/datastore/dataset/compas-recidivism-risk-score-data-and-analysis] data set, the flaws in applying it but also its potential upside if its shortcomings can be overlooked.  We have also spent time in class verbally assessing positions both for an against applying this data set in real life.  In no more than two pages ^[knit to a pdf to ensure page count] take the persona of a statistical  advising a judge as to whether they should include the results of the COMPAS algorithm in their decision making process for granting parole.  First clearly articulate your position (whether the algorithm should be used or not) and then defend said position using both statistical and philosophical evidence.  Your paper will be grade both on the merits of its persuasive appeal but also the applicability of the statistical and philosohpical evidence cited.  


*As a statistical consultant, my recommendation is that the COMPAS algorithm should not be used in parole decision-making. Developed by Northpointe Inc.,  COMPAS algorithm predicts the recidivism risk from a score of 1-10 denoting lowest risk to highest risk. COMPAS evaluates factors like criminal history, personal background, and behavioral indicators to assign a recidivism risk score. While the tool is intended to aid judges in making parole decisions, it has come under scrutiny due to its lack of transparency and documented racial bias. As a statistical consultant, my recommendation is that the COMPAS algorithm should not be used in parole decision-making. The primary reason is that COMPAS has significant shortcomings that may ignore justice and fairness, particularly against certain demographic groups.

From a statistical perspective, multiple measures of statistical fairness are not fulfilled by the COMPAS algorithm. It firstly violates disparate impact by showing biases on race. By using a binary classifier, disparate impact statistically examines whether a seemingly neutral policy or tool disproportionately affects one group more than others without justified reason. From ProPublica investigation, African American defendants are nearly twice as likely to be classified as high risk by COMPAS compared to white defendants. It strongly suggesting that COMPAS is not statistically fair in its predictions across demographic groups. 
Another statistical concern with COMPAS is its failure to meet the criterion of equalized odds, a fairness measure that requires an algorithm to have similar false positive and false negative rates across different demographic groups. However, the ProPublica investigation have highlighted COMPAS’s failure in this regard: it has disproportionately high false positive rates for African American defendants, meaning it often misclassifies them as higher risk for repeated offense than they are. Conversely, COMPAS has shown a higher rate of false negatives for white defendants, categorizing many as lower risk despite a likelihood of repeated offense. This disparity between groups indicates a substantial bias, leading to a system that unjustly penalizes individuals based on race rather than actual risk. The issue with COMPAS goes beyond simple accuracy—it’s about who is inaccurately labeled and the consequences of these labels. For African Americans, an inflated false positive rate means they are unjustly denied parole based on an overestimated risk, leading to longer incarceration times and exacerbating systemic racial inequalities. In contrast, for white defendants, a higher false negative rate may grant parole to individuals who may indeed reoffend, thus posing a risk to public safety. These biases in prediction not only distort the tool’s effectiveness but also fundamentally undermine its credibility as a “fair” risk assessment model.

From a utilitarian standpoint, the primary objective is to maximize overall well-being and minimize harm across society. Although tools like COMPAS are intended to improve judicial efficiency by predicting recidivism risk, the utilitarian approach raises concerns about its potential to cause more harm than good. COMPAS’s biases, lack of transparency, and tendency to misclassify individuals mean that its use in parole decisions may lead to outcomes that decrease societal welfare rather than enhance it.

COMPAS can also be morally opposed. According to Utilitarians, a favorable action should maximize overall well-being and minimize harm across society. As COMPAS disproportionately mislabels African Americans as high risk, unnecessary periods of incarceration for people who may not actually pose a threat are extended. Therefore, unjustly prolonged reduces overall societal well-being. The freedom and opportunity of personal growth of these unfairly treated individuals were disrupted. It will ultimately result in: lost income, broken family ties, and diminished chances of reintegration upon release, all of which can lead to generational cycles of poverty and hardship.

Furthermore, this systematic bias against African Americans contributes to a broader erosion of social justice. Incarcerating people based on flawed assessments exacerbates existing racial inequalities, reinforcing societal patterns of discrimination and exclusion. Communities that experience high rates of incarceration often bear the social and economic burdens of these policies, resulting in decreased access to resources, weakened family structures, and reduced educational and employment opportunities. When one demographic is disproportionately impacted by an algorithm like COMPAS, social justice is compromised, as it creates an uneven situation where African Americans bear greater costs.

Thus, the consequences of using COMPAS to make biased decisions are actually harmful to the society, which is opposed to the utilitarians’ perspectives. By unjustly labeling African Americans as high risk, COMPAS contributes to a system that perpetuates inequality rather than fostering a fair and supportive society, ultimately harming the social fabric and standing in opposition to the principles of social justice and equal treatment.*